{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "header"
            },
            "source": [
                "# \ud83d\udcd8 LSTM for Biogas Prediction (Production Ready)\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/benmola/OpenAD-lib/blob/main/notebooks/03_LSTM_Prediction.ipynb)\n",
                "\n",
                "This notebook demonstrates **LSTM-based biogas prediction** using temporal feature engineering.\n",
                "\n",
                "**\u26a0\ufe0f This notebook matches `examples/04_lstm_prediction.py` exactly**\n",
                "\n",
                "---\n",
                "\n",
                "## \ud83d\udcda References\n",
                "- **LSTM for AD**: [Murali et al. (2025) - LAPSE](https://psecommunity.org/LAPSE:2025.0213)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "theory"
            },
            "source": [
                "## \ud83d\udd2c LSTM Background\n",
                "\n",
                "### Why LSTM for Time-Series?\n",
                "\n",
                "Biogas production depends on **past substrate loading**, making it a time-series problem:\n",
                "- **Input at t-1** affects output at **t**\n",
                "- LSTM's internal memory captures these temporal dependencies\n",
                "\n",
                "### LSTM Cell Equations\n",
                "\n",
                "**Forget Gate** (what to forget from memory):\n",
                "$$f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)$$\n",
                "\n",
                "**Input Gate** (what new info to store):\n",
                "$$i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)$$\n",
                "$$\\tilde{C}_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)$$\n",
                "\n",
                "**Cell State Update**:\n",
                "$$C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t$$\n",
                "\n",
                "**Output Gate**:\n",
                "$$o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)$$\n",
                "$$h_t = o_t \\odot \\tanh(C_t)$$\n",
                "\n",
                "### Key Preprocessing: Time-Lagged Features\n",
                "\n",
                "We use `series_to_supervised()` to create features like:\n",
                "- `Maize(t-1)` \u2192 predicts `Biogas(t)`\n",
                "- `Wholecrop(t-1)` \u2192 predicts `Biogas(t)`\n",
                "\n",
                "This captures the **lag** between feeding and biogas production."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "setup"
            },
            "source": [
                "## 1\ufe0f\u20e3 Setup (Google Colab)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install"
            },
            "outputs": [],
            "source": [
                "# Install OpenAD-lib with ML dependencies (PyTorch, etc.)\n",
                "# !pip install git+https://github.com/benmola/OpenAD-lib.git\n",
                "\n",
                "import sys\n",
                "import os\n",
                "\n",
                "IN_COLAB = 'google.colab' in sys.modules\n",
                "\n",
                "if not IN_COLAB:\n",
                "    sys.path.append(os.path.join(os.getcwd(), '..', 'src'))\n",
                "\n",
                "print(f\"Running in Colab: {IN_COLAB}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "imports"
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
                "\n",
                "from openad_lib.models.ml import LSTMModel\n",
                "\n",
                "print(\"\u2705 All imports successful!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "preprocessing"
            },
            "source": [
                "## 2\ufe0f\u20e3 Time-Series Preprocessing Function\n",
                "\n",
                "**`series_to_supervised()`** transforms time-series into supervised learning format:\n",
                "\n",
                "**Example:**\n",
                "```\n",
                "Original:          Transformed:\n",
                "t   Maize  Biogas  \u2192  Maize(t-1)  Biogas(t)\n",
                "0   10     100         NaN         100\n",
                "1   12     120         10          120\n",
                "2   15     150         12          150\n",
                "```\n",
                "\n",
                "This creates the critical **lag relationship** for prediction."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "series_to_supervised"
            },
            "outputs": [],
            "source": [
                "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
                "    \"\"\"\n",
                "    Convert time series to supervised learning format.\n",
                "    \n",
                "    Args:\n",
                "        data: ndarray or DataFrame - Input time series\n",
                "        n_in: int - Number of lag observations (default=1)\n",
                "        n_out: int - Number of future observations (default=1)  \n",
                "        dropnan: bool - Remove rows with NaN values\n",
                "    \n",
                "    Returns:\n",
                "        DataFrame with lagged features\n",
                "    \"\"\"\n",
                "    n_vars = 1 if type(data) is list else data.shape[1]\n",
                "    df = pd.DataFrame(data)\n",
                "    cols, names = [], []\n",
                "    \n",
                "    # Input sequence (t-n, ... t-1)\n",
                "    for i in range(n_in, 0, -1):\n",
                "        cols.append(df.shift(i))\n",
                "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
                "    \n",
                "    # Forecast sequence (t, t+1, ... t+n)\n",
                "    for i in range(0, n_out):\n",
                "        cols.append(df.shift(-i))\n",
                "        if i == 0:\n",
                "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
                "        else:\n",
                "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
                "    \n",
                "    # Concatenate and remove NaN\n",
                "    agg = pd.concat(cols, axis=1)\n",
                "    agg.columns = names\n",
                "    if dropnan:\n",
                "        agg.dropna(inplace=True)\n",
                "    return agg\n",
                "\n",
                "print(\"\u2705 series_to_supervised() defined\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "data"
            },
            "source": [
                "## 3\ufe0f\u20e3 Load Time-Series Data\n",
                "\n",
                "**Dataset:** `sample_LSTM_timeseries.csv`\n",
                "- **424 daily samples** from a real biogas plant\n",
                "- **Features:** Feedstock composition (Maize, Chicken Litter, etc.) in tonnes/day\n",
                "- **Target:** Total biogas production (m\u00b3/day)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "load_data"
            },
            "outputs": [],
            "source": [
                "# Download data for Colab\n",
                "if IN_COLAB:\n",
                "    !wget -q https://raw.githubusercontent.com/benmola/OpenAD-lib/main/src/openad_lib/data/sample_LSTM_timeseries.csv\n",
                "    data_path = 'sample_LSTM_timeseries.csv'\n",
                "else:\n",
                "    base_path = os.path.dirname(os.getcwd())\n",
                "    data_path = os.path.join(base_path, 'src', 'openad_lib', 'data', 'sample_LSTM_timeseries.csv')\n",
                "\n",
                "# Load and inspect\n",
                "data = pd.read_csv(data_path).dropna()\n",
                "print(f\"\ud83d\udcca Loaded {len(data)} samples\")\n",
                "print(f\"\\nColumns: {list(data.columns)}\")\n",
                "data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "define_features"
            },
            "outputs": [],
            "source": [
                "# Define features and target (MUST match example script)\n",
                "features = ['Maize', 'Wholecrop', 'Chicken Litter', 'Lactose', 'Apple Pomace', 'Rice bran']\n",
                "target = 'Total_Biogas'\n",
                "\n",
                "print(f\"Features (6): {features}\")\n",
                "print(f\"Target: {target}\")\n",
                "print(f\"\\nFeature Matrix shape: {data[features].shape}\")\n",
                "print(f\"Target shape: {data[[target]].shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "preprocessing_steps"
            },
            "source": [
                "## 4\ufe0f\u20e3 Data Preprocessing Pipeline\n",
                "\n",
                "**Critical Steps (MUST be done in this order):**\n",
                "\n",
                "1. **Normalize Features** \u2192 StandardScaler on X  \n",
                "   *Why?* Features have different scales (Maize: 0-50 tonnes, Lactose: 0-5 tonnes)\n",
                "\n",
                "2. **Create Lag Features** \u2192 `series_to_supervised()`  \n",
                "   *Why?* Biogas at day t depends on feeding at day t-1\n",
                "\n",
                "3. **Normalize Target** \u2192 StandardScaler on y  \n",
                "   *Why?* Helps LSTM training convergence\n",
                "\n",
                "4. **80/20 Split** \u2192 Chronological (not random!)  \n",
                "   *Why?* Time-series must preserve temporal order"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "normalize_features"
            },
            "outputs": [],
            "source": [
                "# Step 1: Normalize input features\n",
                "print(\"Step 1: Normalizing features...\")\n",
                "values = data[features].values.astype('float32')\n",
                "scaler_X = StandardScaler()\n",
                "scaled_X = scaler_X.fit_transform(values)\n",
                "\n",
                "print(f\"  Original range: [{values.min():.2f}, {values.max():.2f}]\")\n",
                "print(f\"  Scaled range: [{scaled_X.min():.2f}, {scaled_X.max():.2f}]\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "create_lags"
            },
            "outputs": [],
            "source": [
                "# Step 2: Create time-lagged features\n",
                "print(\"\\nStep 2: Creating lag features...\")\n",
                "reframed = series_to_supervised(scaled_X, n_in=1, n_out=1)\n",
                "\n",
                "print(f\"  Before: {scaled_X.shape} (424 rows \u00d7 6 features)\")\n",
                "print(f\"  After: {reframed.shape} (423 rows \u00d7 12 features)\")\n",
                "print(f\"\\n  New columns: {list(reframed.columns[:6])} ... (t-1 features)\")\n",
                "print(f\"  Plus: {list(reframed.columns[6:])} ... (t features)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "normalize_target"
            },
            "outputs": [],
            "source": [
                "# Step 3: Normalize target variable\n",
                "print(\"\\nStep 3: Normalizing target...\")\n",
                "y = data[[target]].values\n",
                "scaler_y = StandardScaler()\n",
                "y_scaled = scaler_y.fit_transform(y)\n",
                "\n",
                "print(f\"  Original biogas range: [{y.min():.2f}, {y.max():.2f}] m\u00b3/day\")\n",
                "print(f\"  Scaled range: [{y_scaled.min():.2f}, {y_scaled.max():.2f}]\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "train_test_split"
            },
            "outputs": [],
            "source": [
                "# Step 4: 80/20 chronological split\n",
                "print(\"\\nStep 4: Train/test split (80/20)...\")\n",
                "split_idx = int(len(reframed) * 0.8)\n",
                "\n",
                "train = reframed.values[:split_idx]\n",
                "test = reframed.values[split_idx:]\n",
                "\n",
                "# CRITICAL: Last column is target (var7(t) \u2192 biogas at t)\n",
                "# All other columns are features (var1-6 at t-1 and t)\n",
                "train_X, train_y = train[:, :-1], train[:, -1]\n",
                "test_X, test_y = test[:, :-1], test[:, -1]\n",
                "\n",
                "print(f\"  Training samples: {len(train_X)}\")\n",
                "print(f\"  Testing samples: {len(test_X)}\")\n",
                "print(f\"  Train X shape: {train_X.shape} (11 lag features)\")\n",
                "print(f\"  Train y shape: {train_y.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "model_section"
            },
            "source": [
                "## 5\ufe0f\u20e3 Build and Train LSTM Model\n",
                "\n",
                "**Architecture:**\n",
                "- **Input:** 11 features (6 features at t-1, 5 at t, excluding target)\n",
                "- **Hidden:** 24 LSTM units (chosen via hyperparameter tuning)\n",
                "- **Output:** 1 value (biogas prediction)\n",
                "\n",
                "**Training:**\n",
                "- 50 epochs\n",
                "- Adam optimizer (lr=0.001)\n",
                "- MSE loss"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "train_model"
            },
            "outputs": [],
            "source": [
                "# Initialize LSTM (input_dim MUST match train_X.shape[1])\n",
                "print(\"\ud83d\ude80 Training LSTM model...\\n\")\n",
                "lstm = LSTMModel(\n",
                "    input_dim=train_X.shape[1],  # 11 features\n",
                "    hidden_dim=24,\n",
                "    output_dim=1,\n",
                "    num_layers=1,\n",
                "    dropout=0.1,\n",
                "    learning_rate=0.001\n",
                ")\n",
                "\n",
                "# Train (data already scaled)\n",
                "lstm.fit(train_X, train_y, epochs=50, batch_size=4, verbose=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "evaluation"
            },
            "source": [
                "## 6\ufe0f\u20e3 Evaluate Model Performance\n",
                "\n",
                "**Metrics:**\n",
                "- **RMSE** (Root Mean Squared Error): Average prediction error in m\u00b3/day\n",
                "- **MAE** (Mean Absolute Error): Average absolute error\n",
                "- **R\u00b2** (Coefficient of Determination): How well model explains variance (1.0 = perfect)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "predict"
            },
            "outputs": [],
            "source": [
                "# Make predictions (still in scaled space)\n",
                "trainPredict = lstm.predict(train_X)\n",
                "testPredict = lstm.predict(test_X)\n",
                "\n",
                "# CRITICAL: Inverse transform to original scale for interpretation\n",
                "trainPredict_inv = scaler_y.inverse_transform(trainPredict)\n",
                "testPredict_inv = scaler_y.inverse_transform(testPredict)\n",
                "train_y_inv = scaler_y.inverse_transform(train_y.reshape(-1, 1))\n",
                "test_y_inv = scaler_y.inverse_transform(test_y.reshape(-1, 1))\n",
                "\n",
                "print(\"\u2705 Predictions generated and inverse-transformed\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "metrics"
            },
            "outputs": [],
            "source": [
                "# Calculate metrics in original scale\n",
                "train_rmse = np.sqrt(mean_squared_error(train_y_inv, trainPredict_inv))\n",
                "test_rmse = np.sqrt(mean_squared_error(test_y_inv, testPredict_inv))\n",
                "train_mae = mean_absolute_error(train_y_inv, trainPredict_inv)\n",
                "test_mae = mean_absolute_error(test_y_inv, testPredict_inv)\n",
                "train_r2 = r2_score(train_y_inv, trainPredict_inv)\n",
                "test_r2 = r2_score(test_y_inv, testPredict_inv)\n",
                "\n",
                "print(\"\ud83d\udcca LSTM Performance Metrics:\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"Train RMSE: {train_rmse:.2f} m\u00b3/day, Test RMSE: {test_rmse:.2f} m\u00b3/day\")\n",
                "print(f\"Train MAE:  {train_mae:.2f} m\u00b3/day, Test MAE:  {test_mae:.2f} m\u00b3/day\")\n",
                "print(f\"Train R\u00b2:   {train_r2:.3f},        Test R\u00b2:   {test_r2:.3f}\")\n",
                "print(\"\\n\u2705 These metrics should match examples/04_lstm_prediction.py\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "visualization"
            },
            "source": [
                "## 7\ufe0f\u20e3 Visualize Results\n",
                "\n",
                "**Side-by-side comparison:**\n",
                "- **Left:** Training set predictions (should be very good)\n",
                "- **Right:** Testing set predictions (shows generalization ability)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "plot"
            },
            "outputs": [],
            "source": [
                "plt.style.use('bmh')\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
                "\n",
                "# Training set\n",
                "ax1.plot(train_y_inv, label='Actual', color='#2E86C1', alpha=0.7, linewidth=2)\n",
                "ax1.plot(trainPredict_inv, label='LSTM Prediction', color='#E67E22', linestyle='--', linewidth=2)\n",
                "ax1.set_title(f\"Training Set (R\u00b2 = {train_r2:.3f})\", fontsize=14, fontweight='bold')\n",
                "ax1.set_xlabel(\"Sample Index\", fontsize=12)\n",
                "ax1.set_ylabel(\"Biogas Production (m\u00b3/day)\", fontsize=12)\n",
                "ax1.legend(fontsize=11)\n",
                "ax1.grid(True, alpha=0.3)\n",
                "\n",
                "# Testing set  \n",
                "ax2.plot(test_y_inv, label='Actual', color='#2E86C1', alpha=0.7, linewidth=2)\n",
                "ax2.plot(testPredict_inv, label='LSTM Prediction', color='#E67E22', linestyle='--', linewidth=2)\n",
                "ax2.set_title(f\"Testing Set (R\u00b2 = {test_r2:.3f})\", fontsize=14, fontweight='bold')\n",
                "ax2.set_xlabel(\"Sample Index\", fontsize=12)\n",
                "ax2.set_ylabel(\"Biogas Production (m\u00b3/day)\", fontsize=12)\n",
                "ax2.legend(fontsize=11)\n",
                "ax2.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "summary"
            },
            "source": [
                "## \ud83d\udcdd Summary\n",
                "\n",
                "This notebook demonstrated:\n",
                "\n",
                "1. **Temporal Feature Engineering** - `series_to_supervised()` for lag features\n",
                "2. **Proper Scaling** - StandardScaler on both X and y\n",
                "3. **LSTM Training** - 50 epochs with 24 hidden units\n",
                "4. **Evaluation** - RMSE, MAE, R\u00b2 metrics in original scale\n",
                "\n",
                "### \ud83c\udfaf Key Takeaway\n",
                "\n",
                "**Time-lagged features are critical** for biogas prediction because:\n",
                "- Substrate fed at day t-1 \u2192 digested \u2192 biogas at day t\n",
                "- Without lag features, model can't learn this temporal dependency\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "- Compare with [Multi-Task GP](04_MTGP_Prediction.ipynb) for uncertainty quantification\n",
                "- Try [ADM1 mechanistic model](01_ADM1_Tutorial.ipynb) for process understanding\n",
                "- Explore [MPC Control](05_MPC_Control.ipynb) for optimization"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": [],
            "toc_visible": true
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}