{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "header"
            },
            "source": [
                "# üìò Multi-Task Gaussian Process (Production Ready)\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/benmola/OpenAD-lib/blob/main/notebooks/04_MTGP_Prediction_Full.ipynb)\n",
                "\n",
                "Predicting **multiple AD outputs** (SCOD, VFA, Biogas) with **uncertainty quantification**.\n",
                "\n",
                "**‚ö†Ô∏è This notebook matches `examples/05_mtgp_prediction.py` exactly**\n",
                "\n",
                "---\n",
                "\n",
                "## üìö References\n",
                "- **MTGP for AD**: [Dekhici et al. (2025) - LAPSE](https://psecommunity.org/LAPSE:2025.0155)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "theory"
            },
            "source": [
                "## üî¨ Gaussian Process Background\n",
                "\n",
                "### What is a Gaussian Process?\n",
                "\n",
                "A GP defines a **distribution over functions**:\n",
                "\n",
                "$$f(x) \\sim \\mathcal{GP}(m(x), k(x, x'))$$\n",
                "\n",
                "Where:\n",
                "- $m(x)$ = mean function (usually 0)\n",
                "- $k(x, x')$ = **kernel** function measuring similarity\n",
                "\n",
                "### Why GPs for Biogas?\n",
                "\n",
                "1. **Uncertainty Quantification** - Get confidence intervals for free!\n",
                "2. **Data Efficient** - Work well with small datasets (50-200 samples)\n",
                "3. **Non-parametric** - No assumptions about functional form\n",
                "\n",
                "### Multi-Task Learning with LMC\n",
                "\n",
                "**Problem:** Predict 3 correlated outputs (SCOD, VFA, Biogas)\n",
                "\n",
                "**Solution:** Linear Model of Coregionalization (LMC)\n",
                "\n",
                "$$f_t(x) = \\sum_{q=1}^{Q} a_{t,q} \\cdot u_q(x)$$\n",
                "\n",
                "- $f_t$ = function for task $t$ (e.g., VFA prediction)\n",
                "- $u_q$ = shared latent function $q$\n",
                "- $a_{t,q}$ = weight (learned automatically)\n",
                "\n",
                "**Key Insight:** VFA and Biogas are correlated ‚Üí share information!\n",
                "\n",
                "### Predictive Distribution\n",
                "\n",
                "$$p(f_* | X_*, X, Y) = \\mathcal{N}(\\mu_*, \\Sigma_*)$$\n",
                "\n",
                "We get:\n",
                "- **Mean prediction:** $\\mu_*$\n",
                "- **Uncertainty:** $\\pm 2\\sigma_*$ (95% confidence interval)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "setup"
            },
            "source": [
                "## 1Ô∏è‚É£ Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install"
            },
            "outputs": [],
            "source": [
                "# Install with ML dependencies (GPyTorch, PyTorch)\n",
                "!pip install git+https://github.com/benmola/OpenAD-lib.git\n",
                "\n",
                "import sys\n",
                "import os\n",
                "\n",
                "IN_COLAB = 'google.colab' in sys.modules\n",
                "\n",
                "if not IN_COLAB:\n",
                "    sys.path.append(os.path.join(os.getcwd(), '..', 'src'))\n",
                "\n",
                "print(f\"Running in Colab: {IN_COLAB}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "imports"
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from openad_lib.models.ml import MultitaskGP\n",
                "\n",
                "print(\"‚úÖ Imports successful!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "data"
            },
            "source": [
                "## 2Ô∏è‚É£ Load Multi-Output AD Data\n",
                "\n",
                "**Dataset:** `sample_ad_process_data.csv`\n",
                "\n",
                "**Inputs (5):**\n",
                "- `time` - Day number\n",
                "- `D` - Dilution rate (1/day)\n",
                "- `SCODin` - Influent SCOD (g COD/L)\n",
                "- `OLR` - Organic Loading Rate (g COD/L/day)\n",
                "- `pH` - Reactor pH\n",
                "\n",
                "**Outputs (3):** All correlated!\n",
                "- `SCODout` - Effluent SCOD ‚Üí waste\n",
                "- `VFAout` - VFA concentration ‚Üí process stability indicator\n",
                "- `Biogas` - Biogas production ‚Üí revenue\n",
                "\n",
                "**Why predict all 3?** VFA ‚Üë often means Biogas ‚Üì (process inhibition)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "load_data"
            },
            "outputs": [],
            "source": [
                "# Download for Colab\n",
                "if IN_COLAB:\n",
                "    !wget -q https://raw.githubusercontent.com/benmola/OpenAD-lib/main/src/openad_lib/data/sample_ad_process_data.csv\n",
                "    data_path = 'sample_ad_process_data.csv'\n",
                "else:\n",
                "    base_path = os.path.dirname(os.getcwd())\n",
                "    data_path = os.path.join(base_path, 'src', 'openad_lib', 'data', 'sample_ad_process_data.csv')\n",
                "\n",
                "# Load\n",
                "data = pd.read_csv(data_path)\n",
                "print(f\"üìä Loaded {len(data)} samples\")\n",
                "print(f\"\\nColumns: {list(data.columns)}\")\n",
                "data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "define_cols"
            },
            "outputs": [],
            "source": [
                "# CRITICAL: Define columns explicitly (MUST match example)\n",
                "input_cols = ['time', 'D', 'SCODin', 'OLR', 'pH']\n",
                "output_cols = ['SCODout', 'VFAout', 'Biogas']\n",
                "\n",
                "# Verify columns exist\n",
                "missing_inputs = [c for c in input_cols if c not in data.columns]\n",
                "missing_outputs = [c for c in output_cols if c not in data.columns]\n",
                "\n",
                "if missing_inputs or missing_outputs:\n",
                "    print(f\"‚ùå Missing columns!\")\n",
                "    print(f\"   Inputs: {missing_inputs}\")\n",
                "    print(f\"   Outputs: {missing_outputs}\")\n",
                "else:\n",
                "    print(\"‚úÖ All columns found\")\n",
                "    \n",
                "# Extract data\n",
                "X = data[input_cols].values\n",
                "Y = data[output_cols].values\n",
                "\n",
                "print(f\"\\nInput shape: {X.shape} (5 features)\")\n",
                "print(f\"Output shape: {Y.shape} (3 tasks)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "split"
            },
            "source": [
                "## 3Ô∏è‚É£ Train/Test Split Strategy\n",
                "\n",
                "**Alternating Split** (not random!):\n",
                "\n",
                "```\n",
                "Original:  0  1  2  3  4  5  6  7  8  9 ...\n",
                "Test:      ‚úì     ‚úì     ‚úì     ‚úì     ‚úì    ... (even indices)\n",
                "Train:        ‚úì     ‚úì     ‚úì     ‚úì   ...    (odd indices)\n",
                "```\n",
                "\n",
                "**Why alternating?**\n",
                "- Tests interpolation ability (realistic for AD)\n",
                "- Preserves temporal distribution\n",
                "- Avoids train/test distribution shift\n",
                "\n",
                "**From reference paper:** This split maximizes GP's strength in smooth interpolation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "split_data"
            },
            "outputs": [],
            "source": [
                "# Alternating indices (MUST match example)\n",
                "train_indices = np.arange(1, len(X), 2)  # [1, 3, 5, 7, ...]\n",
                "test_indices = np.arange(0, len(X), 2)   # [0, 2, 4, 6, ...]\n",
                "\n",
                "X_train, X_test = X[train_indices], X[test_indices]\n",
                "Y_train, Y_test = Y[train_indices], Y[test_indices]\n",
                "\n",
                "print(f\"Training samples: {len(X_train)}\")\n",
                "print(f\"Testing samples: {len(X_test)}\")\n",
                "print(f\"\\nSplit ratio: {len(X_train)/(len(X_train)+len(X_test)):.1%} train\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "model"
            },
            "source": [
                "## 4Ô∏è‚É£ MTGP Model Configuration\n",
                "\n",
                "**Hyperparameters (tuned via validation):**\n",
                "\n",
                "| Parameter | Value | Purpose |\n",
                "|-----------|-------|----------|\n",
                "| `num_tasks` | 3 | Number of outputs (SCOD, VFA, Biogas) |\n",
                "| `num_latents` | 3 | Shared latent functions for LMC |\n",
                "| `n_inducing` | 60 | Inducing points for scalability |\n",
                "| `learning_rate` | 0.1 | Adam optimizer LR |\n",
                "| `log_transform` | True | Handle positive-only outputs |\n",
                "\n",
                "**Why these values?**\n",
                "- `num_latents=3`: Each task gets its own latent + sharing\n",
                "- `n_inducing=60`: ~50% of training data (good for ~100 samples)\n",
                "- `log_transform`: Biogas/VFA can't be negative!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "init_model"
            },
            "outputs": [],
            "source": [
                "# Initialize MTGP (MUST match example hyperparameters)\n",
                "num_tasks = Y.shape[1]\n",
                "print(f\"üîß Initializing MTGP with {num_tasks} tasks...\")\n",
                "\n",
                "mtgp = MultitaskGP(\n",
                "    num_tasks=num_tasks,\n",
                "    num_latents=min(3, num_tasks),  # Cap at 3 latent functions\n",
                "    n_inducing=60,\n",
                "    learning_rate=0.1,\n",
                "    log_transform=True  # Critical for positive outputs!\n",
                ")\n",
                "\n",
                "print(\"‚úÖ Model initialized\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "training"
            },
            "source": [
                "## 5Ô∏è‚É£ Train MTGP Model\n",
                "\n",
                "**Training Process:**\n",
                "1. Optimize kernel hyperparameters (lengthscales, variance)\n",
                "2. Learn task correlations (LMC weights $a_{t,q}$)\n",
                "3. Update inducing point locations\n",
                "\n",
                "**500 epochs** - typical for variational GP training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "train"
            },
            "outputs": [],
            "source": [
                "print(\"üöÄ Training MTGP (500 iterations)...\\n\")\n",
                "mtgp.fit(X_train, Y_train, epochs=500, verbose=True)\n",
                "print(\"\\n‚úÖ Training complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "prediction"
            },
            "source": [
                "## 6Ô∏è‚É£ Predict with Uncertainty\n",
                "\n",
                "**GP provides 3 values for each prediction:**\n",
                "\n",
                "1. **Mean** ($\\mu_*$): Best estimate\n",
                "2. **Lower bound** ($\\mu_* - 2\\sigma_*$): 2.5th percentile\n",
                "3. **Upper bound** ($\\mu_* + 2\\sigma_*$): 97.5th percentile\n",
                "\n",
                "**95% Confidence Interval = [Lower, Upper]**\n",
                "\n",
                "**Uncertainty types:**\n",
                "- **Aleatoric**: Data noise (irreducible)\n",
                "- **Epistemic**: Model uncertainty (reduces with more data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "predict"
            },
            "outputs": [],
            "source": [
                "print(\"üîÆ Predicting on test set with uncertainty...\")\n",
                "mean, lower, upper = mtgp.predict(X_test, return_std=True)\n",
                "\n",
                "print(f\"\\nPrediction shapes:\")\n",
                "print(f\"  Mean: {mean.shape}\")\n",
                "print(f\"  Lower (2.5%): {lower.shape}\")\n",
                "print(f\"  Upper (97.5%): {upper.shape}\")\n",
                "\n",
                "# Average uncertainty width per task\n",
                "for i, task in enumerate(output_cols):\n",
                "    avg_width = (upper[:, i] - lower[:, i]).mean()\n",
                "    print(f\"  {task}: Avg CI width = {avg_width:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "evaluation"
            },
            "source": [
                "## 7Ô∏è‚É£ Evaluate Performance\n",
                "\n",
                "**Metrics per task:**\n",
                "- **RMSE**: Prediction error magnitude\n",
                "- **MAE**: Average absolute error\n",
                "- **R¬≤**: Variance explained (1.0 = perfect)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "evaluate"
            },
            "outputs": [],
            "source": [
                "metrics = mtgp.evaluate(X_test, Y_test, task_names=output_cols)\n",
                "\n",
                "print(\"üìä MTGP Test Metrics:\")\n",
                "print(\"=\" * 60)\n",
                "for task, vals in metrics.items():\n",
                "    print(f\"{task:10s}: RMSE={vals['rmse']:.4f}, MAE={vals['mae']:.4f}, R¬≤={vals['r2']:.4f}\")\n",
                "print(\"\\n‚úÖ These metrics should match examples/05_mtgp_prediction.py\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "visualization"
            },
            "source": [
                "## 8Ô∏è‚É£ Visualize Predictions with Uncertainty\n",
                "\n",
                "**Each subplot shows:**\n",
                "- üîµ **Blue dots** = Training data\n",
                "- üî¥ **Red dots** = Test data (ground truth)\n",
                "- ‚¨õ **Black line** = GP mean prediction\n",
                "- üå´Ô∏è **Gray band** = 95% confidence interval\n",
                "\n",
                "**How to interpret:**\n",
                "- **Narrow CI** = Model is confident (lots of nearby training data)\n",
                "- **Wide CI** = Model is uncertain (sparse data region)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "plot"
            },
            "outputs": [],
            "source": [
                "plt.style.use('bmh')\n",
                "fig, axes = plt.subplots(num_tasks, 1, figsize=(12, 4*num_tasks), sharex=True)\n",
                "\n",
                "for i, (ax, task) in enumerate(zip(axes, output_cols)):\n",
                "    # Training data (blue dots)\n",
                "    ax.plot(X_train[:, 0], Y_train[:, i], 'o', \n",
                "            color='#2E86C1', markersize=5, alpha=0.5, label='Train Data')\n",
                "    \n",
                "    # Test data (red dots)\n",
                "    ax.plot(X_test[:, 0], Y_test[:, i], 'o', \n",
                "            color='#E74C3C', markersize=6, alpha=0.7, label='Test Data (True)')\n",
                "    \n",
                "    # GP mean prediction (black line)\n",
                "    ax.plot(X_test[:, 0], mean[:, i], '-', \n",
                "            color='black', linewidth=2, label='MTGP Mean')\n",
                "    \n",
                "    # 95% Confidence interval (gray band)\n",
                "    ax.fill_between(X_test[:, 0], lower[:, i], upper[:, i],\n",
                "                    color='gray', alpha=0.3, label='95% Confidence')\n",
                "    \n",
                "    ax.set_ylabel(task, fontsize=14, fontweight='bold')\n",
                "    ax.set_title(f'{task} - R¬≤ = {metrics[task][\"r2\"]:.3f}', fontsize=14, pad=10)\n",
                "    ax.legend(fontsize=11, loc='best')\n",
                "    ax.grid(True, linestyle='--', alpha=0.7)\n",
                "\n",
                "axes[-1].set_xlabel('Time (days)', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "summary"
            },
            "source": [
                "## üìù Summary\n",
                "\n",
                "This notebook demonstrated:\n",
                "\n",
                "1. **Multi-Task GP** - Predicting 3 correlated outputs jointly\n",
                "2. **LMC Framework** - Sharing information across tasks\n",
                "3. **Uncertainty Quantification** - 95% confidence intervals\n",
                "4. **Alternating Split** - Realistic interpolation evaluation\n",
                "\n",
                "### üéØ Key Advantages of MTGP\n",
                "\n",
                "| Feature | MTGP | LSTM |\n",
                "|---------|------|------|\n",
                "| **Uncertainty** | ‚úÖ Built-in CI | ‚ùå Needs ensembles |\n",
                "| **Multi-output** | ‚úÖ Correlated sharing | ‚ùå Independent |\n",
                "| **Small data** | ‚úÖ Works with 50-100 | ‚ùå Needs 500+ |\n",
                "| **Interpretability** | ‚úÖ Kernel inspection | ‚ùå Black box |\n",
                "\n",
                "### üìö When to Use MTGP?\n",
                "\n",
                "‚úÖ **Use MTGP when:**\n",
                "- You need **uncertainty estimates** for decision-making\n",
                "- You have **limited data** (<200 samples)\n",
                "- Outputs are **correlated** (VFA ‚Üî Biogas)\n",
                "- You need **confidence intervals** for safety-critical applications\n",
                "\n",
                "‚ùå **Use LSTM instead when:**\n",
                "- Strong temporal dependencies (long time lags)\n",
                "- Large datasets (>1000 samples)\n",
                "- Computational speed critical\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "- Compare with [LSTM](03_LSTM_Prediction_Full.ipynb)\n",
                "- Apply to [MPC Control](05_MPC_Control_Full.ipynb) with uncertainty\n",
                "- See [ADM1](01_ADM1_Tutorial_Full.ipynb) for mechanistic modeling"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": [],
            "toc_visible": true
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
