{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Multi-Task Gaussian Process Tutorial\n",
                "\n",
                "This notebook demonstrates how to use **MultitaskGP** from OpenAD-lib for multi-output prediction with uncertainty quantification.\n",
                "\n",
                "## Overview\n",
                "\n",
                "Multi-Task GPs are excellent for:\n",
                "- Predicting multiple correlated outputs simultaneously\n",
                "- Quantifying prediction uncertainty (confidence intervals)\n",
                "- Learning correlations between output tasks\n",
                "- Working with limited training data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "\n",
                "# Add library to path if not installed\n",
                "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Import MultitaskGP Model\n",
                "from openad_lib.models.ml import MultitaskGP\n",
                "\n",
                "print(\"Imports successful!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load and Explore Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load sample data\n",
                "DATA_DIR = os.path.join(os.path.dirname(os.getcwd()), 'src', 'openad_lib', 'data')\n",
                "data_path = os.path.join(DATA_DIR, 'sample_ad_process_data.csv')\n",
                "\n",
                "data = pd.read_csv(data_path)\n",
                "\n",
                "print(f\"Dataset shape: {data.shape}\")\n",
                "print(f\"\\nColumns:\")\n",
                "print(data.columns.tolist())\n",
                "\n",
                "data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Explore the data\n",
                "print(\"=== Data Statistics ===\")\n",
                "data.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize outputs\n",
                "output_cols = ['SCODout', 'VFAout', 'Biogas']\n",
                "\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "for i, col in enumerate(output_cols):\n",
                "    if col in data.columns:\n",
                "        axes[i].plot(data['time'], data[col], 'b-', linewidth=1)\n",
                "        axes[i].set_xlabel('Time')\n",
                "        axes[i].set_ylabel(col)\n",
                "        axes[i].set_title(f'{col} Over Time')\n",
                "        axes[i].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Correlation between outputs\n",
                "output_data = data[output_cols]\n",
                "corr = output_data.corr()\n",
                "\n",
                "print(\"=== Output Correlations ===\")\n",
                "print(corr)\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(6, 5))\n",
                "im = ax.imshow(corr, cmap='coolwarm', vmin=-1, vmax=1)\n",
                "ax.set_xticks(range(len(output_cols)))\n",
                "ax.set_yticks(range(len(output_cols)))\n",
                "ax.set_xticklabels(output_cols)\n",
                "ax.set_yticklabels(output_cols)\n",
                "plt.colorbar(im)\n",
                "plt.title('Output Correlations')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Prepare Multi-Output Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define inputs and outputs\n",
                "input_cols = ['time', 'D', 'SCODin', 'OLR']\n",
                "output_cols = ['SCODout', 'VFAout', 'Biogas']\n",
                "\n",
                "X = data[input_cols].values\n",
                "Y = data[output_cols].values\n",
                "\n",
                "print(f\"Inputs: {input_cols}\")\n",
                "print(f\"Outputs: {output_cols}\")\n",
                "print(f\"\\nX shape: {X.shape}\")\n",
                "print(f\"Y shape: {Y.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split data (temporal order)\n",
                "train_size = int(len(X) * 0.8)\n",
                "\n",
                "X_train = X[:train_size]\n",
                "X_test = X[train_size:]\n",
                "Y_train = Y[:train_size]\n",
                "Y_test = Y[train_size:]\n",
                "\n",
                "print(f\"Training samples: {len(X_train)}\")\n",
                "print(f\"Testing samples: {len(X_test)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Create and Train MTGP Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create MTGP model\n",
                "mtgp = MultitaskGP(\n",
                "    num_tasks=3,          # 3 outputs (SCOD, VFA, Biogas)\n",
                "    num_latents=3,        # 3 latent functions (LMC)\n",
                "    n_inducing=50,        # Inducing points\n",
                "    learning_rate=0.1,\n",
                "    log_transform=True    # Log-transform outputs\n",
                ")\n",
                "\n",
                "print(f\"MTGP Model Configuration:\")\n",
                "print(f\"  Number of tasks: {mtgp.num_tasks}\")\n",
                "print(f\"  Number of latents: {mtgp.num_latents}\")\n",
                "print(f\"  Inducing points: {mtgp.n_inducing}\")\n",
                "print(f\"  Device: {mtgp.device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train the model\n",
                "print(\"Training MTGP model...\\n\")\n",
                "\n",
                "mtgp.fit(X_train, Y_train, epochs=150, verbose=True)\n",
                "\n",
                "print(\"\\nTraining complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot training loss\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.plot(mtgp.training_losses, 'b-', linewidth=1)\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Negative ELBO')\n",
                "plt.title('Training Loss Over Epochs')\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Predictions with Uncertainty"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get predictions with confidence intervals\n",
                "mean, lower, upper = mtgp.predict(X_test, return_std=True)\n",
                "\n",
                "print(f\"Predictions shape: {mean.shape}\")\n",
                "print(f\"Lower bound shape: {lower.shape}\")\n",
                "print(f\"Upper bound shape: {upper.shape}\")\n",
                "print(\"\\n95% confidence intervals available for all outputs!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate performance\n",
                "metrics = mtgp.evaluate(X_test, Y_test, task_names=output_cols)\n",
                "\n",
                "print(\"=== Test Metrics ===\")\n",
                "for task, m in metrics.items():\n",
                "    print(f\"\\n{task}:\")\n",
                "    print(f\"  RMSE: {m['rmse']:.2f}\")\n",
                "    print(f\"  MAE:  {m['mae']:.2f}\")\n",
                "    print(f\"  R²:   {m['r2']:.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Visualize Predictions with Uncertainty"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot predictions with confidence intervals\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "for i, (name, ax) in enumerate(zip(output_cols, axes)):\n",
                "    x_axis = range(len(Y_test))\n",
                "    \n",
                "    # Actual values\n",
                "    ax.plot(x_axis, Y_test[:, i], 'b.', label='Actual', markersize=8)\n",
                "    \n",
                "    # Predicted mean\n",
                "    ax.plot(x_axis, mean[:, i], 'r-', label='Predicted', linewidth=2)\n",
                "    \n",
                "    # 95% confidence interval\n",
                "    ax.fill_between(x_axis, lower[:, i], upper[:, i], \n",
                "                    alpha=0.3, color='red', label='95% CI')\n",
                "    \n",
                "    ax.set_xlabel('Sample Index')\n",
                "    ax.set_ylabel(name)\n",
                "    ax.set_title(f'{name} (R² = {metrics[name][\"r2\"]:.3f})')\n",
                "    ax.legend()\n",
                "    ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training predictions\n",
                "train_mean, train_lower, train_upper = mtgp.predict(X_train, return_std=True)\n",
                "\n",
                "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
                "\n",
                "for i, name in enumerate(output_cols):\n",
                "    # Training\n",
                "    axes[0, i].plot(Y_train[:, i], train_mean[:, i], 'b.', alpha=0.5)\n",
                "    axes[0, i].plot([Y_train[:, i].min(), Y_train[:, i].max()], \n",
                "                    [Y_train[:, i].min(), Y_train[:, i].max()], 'r--')\n",
                "    axes[0, i].set_xlabel(f'Actual {name}')\n",
                "    axes[0, i].set_ylabel(f'Predicted {name}')\n",
                "    axes[0, i].set_title(f'Training: {name}')\n",
                "    \n",
                "    # Testing\n",
                "    axes[1, i].plot(Y_test[:, i], mean[:, i], 'g.', alpha=0.5)\n",
                "    axes[1, i].plot([Y_test[:, i].min(), Y_test[:, i].max()], \n",
                "                    [Y_test[:, i].min(), Y_test[:, i].max()], 'r--')\n",
                "    axes[1, i].set_xlabel(f'Actual {name}')\n",
                "    axes[1, i].set_ylabel(f'Predicted {name}')\n",
                "    axes[1, i].set_title(f'Testing: {name}')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Uncertainty Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate uncertainty width\n",
                "uncertainty = upper - lower\n",
                "\n",
                "print(\"=== Uncertainty Analysis ===\")\n",
                "for i, name in enumerate(output_cols):\n",
                "    # Check if actual values fall within CI\n",
                "    within_ci = (Y_test[:, i] >= lower[:, i]) & (Y_test[:, i] <= upper[:, i])\n",
                "    coverage = np.mean(within_ci) * 100\n",
                "    \n",
                "    print(f\"\\n{name}:\")\n",
                "    print(f\"  Mean uncertainty width: {np.mean(uncertainty[:, i]):.2f}\")\n",
                "    print(f\"  95% CI coverage: {coverage:.1f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot uncertainty distribution\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "for i, name in enumerate(output_cols):\n",
                "    axes[i].hist(uncertainty[:, i], bins=20, edgecolor='black', alpha=0.7)\n",
                "    axes[i].axvline(np.mean(uncertainty[:, i]), color='red', linestyle='--', \n",
                "                    label=f'Mean: {np.mean(uncertainty[:, i]):.2f}')\n",
                "    axes[i].set_xlabel('Uncertainty Width')\n",
                "    axes[i].set_ylabel('Frequency')\n",
                "    axes[i].set_title(f'{name} Uncertainty Distribution')\n",
                "    axes[i].legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Save and Load Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the model\n",
                "model_path = 'mtgp_ad_model.pt'\n",
                "mtgp.save(model_path)\n",
                "print(f\"Model saved to {model_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the model (requires sample data)\n",
                "loaded_mtgp = MultitaskGP.load(model_path, X_train[:10])\n",
                "print(\"Model loaded successfully!\")\n",
                "\n",
                "# Verify predictions\n",
                "loaded_mean, _, _ = loaded_mtgp.predict(X_test[:5], return_std=True)\n",
                "original_mean, _, _ = mtgp.predict(X_test[:5], return_std=True)\n",
                "\n",
                "print(f\"\\nVerification (first prediction for each task):\")\n",
                "for i, name in enumerate(output_cols):\n",
                "    print(f\"  {name}: Original={original_mean[0, i]:.2f}, Loaded={loaded_mean[0, i]:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Comparison: MTGP vs Single-Task GP\n",
                "\n",
                "MTGP learns correlations between outputs, which can improve predictions when outputs are related.\n",
                "\n",
                "Key advantages:\n",
                "- Shares information across tasks\n",
                "- More data-efficient\n",
                "- Captures output correlations\n",
                "- Natural uncertainty quantification"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary metrics\n",
                "print(\"=== MTGP Performance Summary ===\")\n",
                "print(\"\\n| Task | RMSE | MAE | R² |\")\n",
                "print(\"|------|------|-----|-------|\")\n",
                "for name in output_cols:\n",
                "    m = metrics[name]\n",
                "    print(f\"| {name} | {m['rmse']:.2f} | {m['mae']:.2f} | {m['r2']:.3f} |\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "In this notebook, you learned how to:\n",
                "\n",
                "1. **Load and explore** multi-output AD process data\n",
                "2. **Configure** MTGP with Linear Model of Coregionalization\n",
                "3. **Train** the model with variational inference\n",
                "4. **Predict** with 95% confidence intervals\n",
                "5. **Analyze** uncertainty and coverage\n",
                "6. **Save and load** trained models\n",
                "\n",
                "### Key Takeaways\n",
                "\n",
                "- MTGP is ideal when you need **uncertainty quantification**\n",
                "- It works well with **limited training data**\n",
                "- Outputs should be **correlated** for best results\n",
                "- 95% CI provides **reliability bounds** for predictions\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "- Try different numbers of latent functions\n",
                "- Experiment with different kernel functions\n",
                "- Compare with LSTM for point predictions\n",
                "- Use uncertainty for decision-making in control"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}